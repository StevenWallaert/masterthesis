---
title: Feature Discovery in Small-Sized Experiments in Early Drug Development
author:
  - name: Steven Wallaert
  - name: Promotor&#58; Prof. Dr. Ir. Olivier Thas

column_numbers: 3
logoright_name: https&#58;//raw.githubusercontent.com/brentthorne/posterdown/master/images/betterhexlogo.png
logoleft_name: ugent_logo.png
output: 
  posterdown::posterdown_html:
    self_contained: false
bibliography: packages.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
 
# Introduction

As we currently reside in the era of big data, artificial intelligence and machine learning methods are on a rising tide. Interest in these methods are ever increasing since constrains in terms of computing power, storage capacity and connectivity are less of a concern. However, in certain technological settings data gathering is still limited in sample size due to high costs and limited resources. More specifically, in early drug development research high throughput techniques such as .... and .... are often used in small-sized experiments. The high dimensional data sets produced by these experiments often include tens of thousands of features and only 10 to 50 observations. Researchers in this field hope they can exploit the power of machine learning and AI to make more and better discoveries that would eventually lead to new and better drugs. Yet, since their main application is in situations where data sets consist of thousands or even millions of observations and only a fraction of features, little is known about how these ML techniques empirically perform. As such, it is unclear how these data sets in early drug discovery are best approached.

## Objectives

1. Gain insight in how researchers within this field analyzed these kinds of data in the recent years.
2. Perform a simulation study comparing the most relevant methods in varying realistic conditions.
3. Formulate clear data analysis guidelines
4. Exemplify by means of a data analysis of real data

# Methods

1. Literature review
2. Simulation study
  - Aim: 
  - Data generating mechanisms
  - Estimands
  - Methods
  - Performance metrics

# Results

Usually you want to have a nice table displaying some important results that you have calculated. In `posterdown` this is as easy as using the `kable` table formatting you are probably use to as per typical R Markdown formatting.

You can reference tables like so: Table \@ref(tab:mytable). Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam placerat augue at velit tincidunt semper. Donec elementum porta posuere. Nullam interdum, odio at tincidunt feugiat, turpis nisi blandit eros, eu posuere risus felis non quam. Nam eget lorem odio. Duis et aliquet orci. Phasellus nec viverra est.

```{r mytable, out.width='80%'}
knitr::kable(iris[1:10, 1:4], caption = 'Table caption.',align = 'c',"html")
```

Or with figures: Figure \@ref(fig:standard-plot), or Figure \@ref(fig:morefigs).

```{r standard-plot, out.width='80%', fig.align='center', fig.cap='Great figure!', fig.height=5}
plot(mtcars[1:2])
```

```{r morefigs, out.width='80%', echo=TRUE, fig.cap='Amazing, right?!', fig.height=5}
data <- iris

plot(x = data$Sepal.Length, 
     y = data$Sepal.Width, 
     col = data$Species,
     pch = 19, 
     xlab = "Sepal Length (cm)",
     ylab = "Sepal Width (cm)")

```

# Next Steps

A B C

AB BC

ABC

# Conclusion

Try `posterdown` out! Hopefully you like it!

```{r, include=FALSE}
knitr::write_bib(c('knitr','rmarkdown','posterdown','pagedown'), 'packages.bib')
```

# References
